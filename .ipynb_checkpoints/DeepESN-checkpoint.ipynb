{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepESN <br/>\n",
    "https://github.com/gallicch/DeepRC-TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from DeepRC import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df['comment_text'] = df['comment_text'].map(lambda com : clean_text(com))\n",
    "\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "num_classes = len(categories)\n",
    "train, valid = train_test_split(df, random_state=42, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106912, 500, 1) (52659, 500, 1)\n",
      "(106912, 6) (52659, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.comment_text\n",
    "y_train = train[categories]\n",
    "X_valid = valid.comment_text\n",
    "y_valid = valid[categories]\n",
    "\n",
    "tokenizer = Tokenizer(num_words=500)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_matrix(X_train, mode='tfidf')\n",
    "X_valid = tokenizer.texts_to_matrix(X_valid, mode='tfidf')\n",
    "\n",
    "X_train = tf.expand_dims(X_train, axis=2)\n",
    "X_valid = tf.expand_dims(X_valid, axis=2)\n",
    "\n",
    "y_train = y_train.values\n",
    "y_valid = y_valid.values\n",
    "\n",
    "print(X_train.shape,X_valid.shape)\n",
    "print(y_train.shape,y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_units = 100\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "\n",
    "inputs = Input(shape=(reservoir_units,))\n",
    "outputs = Dense(num_classes, activation='softmax')(inputs)\n",
    "readout = Model(inputs, outputs)\n",
    "readout.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "for b in range(0, len(X_train), batch_size):\n",
    "    X = X_train[b:b+batch_size]\n",
    "    y = y_train[b:b+batch_size]\n",
    "    \n",
    "    reservoir = SimpleDeepReservoirLayer(units=reservoir_units, layers=5)(X)\n",
    "    print(reservoir.shape,y.shape)\n",
    "    readout.fit(reservoir, y, epochs=1, verbose=1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic",
   "language": "python",
   "name": "toxic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
